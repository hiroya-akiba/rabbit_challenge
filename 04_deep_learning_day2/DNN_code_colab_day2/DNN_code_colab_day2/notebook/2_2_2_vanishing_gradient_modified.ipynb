{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('TE-BF': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"2_2_2_vanishing_gradient_modified.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"interpreter":{"hash":"2c3a34dd19fbdd77fd1dec8c9940eb4c5c35bf3189654ec1682d5f40120b0240"}},"cells":[{"cell_type":"markdown","source":["# 準備"],"metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"}},{"cell_type":"markdown","source":["## Google Colab 用の処理\r\n","\r\n","下記を実行します\r\n","- ドライブのマウント\r\n","- ノートブックファイルと同じフォルダへの移動 \r\n","\r\n","Googleドライブのマイドライブ を基準に DNN_code/DNN_code_colab_day2 フォルダを置くことを仮定しています。必要に応じて，パスを変更してください．"],"metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# Google Colab での実行かを調べる\r\n","import sys\r\n","import os\r\n","ENV_COLAB = True  if 'google.colab' in sys.modules else False \r\n","\r\n","# google drive のマウント\r\n","if ENV_COLAB:\r\n","  from google.colab import drive \r\n","  drive.mount('/content/drive')\r\n","  os.chdir('/content/drive/My Drive/DNN_code/DNN_code_colab_day2/notebook')"],"outputs":[],"metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## sys.pathの設定"],"metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import sys\r\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定"],"outputs":[],"metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["# vanishing gradient modified"],"metadata":{"id":"bzqCnMTHjkBy","colab_type":"text"}},{"cell_type":"markdown","source":["## multi layer network class"],"metadata":{"id":"k7YjYrTIjkB0","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","from common import layers\r\n","from collections import OrderedDict\r\n","from common import functions\r\n","from data.mnist import load_mnist\r\n","import matplotlib.pyplot as plt\r\n","\r\n","\r\n","class MultiLayerNet:\r\n","    '''\r\n","    input_size: 入力層のノード数\r\n","    hidden_size_list: 隠れ層のノード数のリスト\r\n","    output_size: 出力層のノード数\r\n","    activation: 活性化関数\r\n","    weight_init_std: 重みの初期化方法\r\n","    '''\r\n","    def __init__(self, input_size, hidden_size_list, output_size, activation='relu', weight_init_std='relu'):\r\n","        self.input_size = input_size\r\n","        self.output_size = output_size\r\n","        self.hidden_size_list = hidden_size_list\r\n","        self.hidden_layer_num = len(hidden_size_list)\r\n","        self.params = {}\r\n","\r\n","        # 重みの初期化\r\n","        self.__init_weight(weight_init_std)\r\n","\r\n","        # レイヤの生成, sigmoidとreluのみ扱う\r\n","        activation_layer = {'sigmoid': layers.Sigmoid, 'relu': layers.Relu}\r\n","        self.layers = OrderedDict() # 追加した順番に格納\r\n","        for idx in range(1, self.hidden_layer_num+1):\r\n","            self.layers['Affine' + str(idx)] = layers.Affine(self.params['W' + str(idx)], self.params['b' + str(idx)])\r\n","            self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\r\n","\r\n","        idx = self.hidden_layer_num + 1\r\n","        self.layers['Affine' + str(idx)] = layers.Affine(self.params['W' + str(idx)], self.params['b' + str(idx)])\r\n","\r\n","        self.last_layer = layers.SoftmaxWithLoss()\r\n","\r\n","    def __init_weight(self, weight_init_std):\r\n","        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\r\n","        for idx in range(1, len(all_size_list)):\r\n","            scale = weight_init_std\r\n","            if str(weight_init_std).lower() in ('relu', 'he'):\r\n","                scale = np.sqrt(2.0 / all_size_list[idx - 1])\r\n","            elif str(weight_init_std).lower() in ('sigmoid', 'xavier'):\r\n","                scale = np.sqrt(1.0 / all_size_list[idx - 1])\r\n","\r\n","            self.params['W' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])\r\n","            self.params['b' + str(idx)] = np.zeros(all_size_list[idx])\r\n","\r\n","    def predict(self, x):\r\n","        for layer in self.layers.values():\r\n","            x = layer.forward(x)\r\n","\r\n","        return x\r\n","\r\n","    def loss(self, x, d):\r\n","        y = self.predict(x)\r\n","\r\n","        weight_decay = 0\r\n","        for idx in range(1, self.hidden_layer_num + 2):\r\n","            W = self.params['W' + str(idx)]\r\n","\r\n","        return self.last_layer.forward(y, d) + weight_decay\r\n","\r\n","    def accuracy(self, x, d):\r\n","        y = self.predict(x)\r\n","        y = np.argmax(y, axis=1)\r\n","        if d.ndim != 1 : d = np.argmax(d, axis=1)\r\n","\r\n","        accuracy = np.sum(y == d) / float(x.shape[0])\r\n","        return accuracy\r\n","\r\n","    def gradient(self, x, d):\r\n","        # forward\r\n","        self.loss(x, d)\r\n","\r\n","        # backward\r\n","        dout = 1\r\n","        dout = self.last_layer.backward(dout)\r\n","\r\n","        layers = list(self.layers.values())\r\n","        layers.reverse()\r\n","        for layer in layers:\r\n","            dout = layer.backward(dout)\r\n","\r\n","        # 設定\r\n","        grad = {}\r\n","        for idx in range(1, self.hidden_layer_num+2):\r\n","            grad['W' + str(idx)] = self.layers['Affine' + str(idx)].dW\r\n","            grad['b' + str(idx)] = self.layers['Affine' + str(idx)].db\r\n","\r\n","        return grad\r\n"],"outputs":[],"metadata":{"id":"9am1mx9XjkB0","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## vanishing sample\n","## sigmoid - gauss"],"metadata":{"id":"wnttJnKTjkB4","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01)\r\n","\r\n","iters_num = 2000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.1\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        network.params[key] -= learning_rate * grad[key]\r\n","    \r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)\r\n","    \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"h_2Y_WjfjkB4","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## ReLU - gauss"],"metadata":{"id":"HGfJdqybjkB8","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='relu', weight_init_std=0.01)\r\n","\r\n","iters_num = 2000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.1\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        network.params[key] -= learning_rate * grad[key]\r\n","    \r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)\r\n","    \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"B-UQOGoDjkB9","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## sigmoid - Xavier"],"metadata":{"id":"gkJ0uLg2jkB_","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std='Xavier')\r\n","\r\n","iters_num = 2000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.1\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        network.params[key] -= learning_rate * grad[key]\r\n","    \r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)\r\n","    \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"SYmBuu8TjkCA","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## ReLU - He"],"metadata":{"id":"acD7sHJBjkCC","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='relu', weight_init_std='He')\r\n","\r\n","iters_num = 2000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.1\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        network.params[key] -= learning_rate * grad[key]\r\n","    \r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)\r\n","    \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"sL5lBOxZjkCD","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","## [try] hidden_size_listの数字を変更してみよう"],"metadata":{"id":"5-bUqT-1jkCF","colab_type":"text"}},{"cell_type":"markdown","source":["## [try] sigmoid - He と relu - Xavier についても試してみよう\n","----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"],"metadata":{"id":"5yrUHDe6jkCG","colab_type":"text"}}]}