{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('TE-BF': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"2_5_overfiting.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"interpreter":{"hash":"2c3a34dd19fbdd77fd1dec8c9940eb4c5c35bf3189654ec1682d5f40120b0240"}},"cells":[{"cell_type":"markdown","source":["# 準備"],"metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"}},{"cell_type":"markdown","source":["## Google Colab 用の処理\r\n","\r\n","下記を実行します\r\n","- ドライブのマウント\r\n","- ノートブックファイルと同じフォルダへの移動 \r\n","\r\n","Googleドライブのマイドライブ を基準に DNN_code/DNN_code_colab_day2 フォルダを置くことを仮定しています。必要に応じて，パスを変更してください．"],"metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# Google Colab での実行かを調べる\r\n","import sys\r\n","import os\r\n","ENV_COLAB = True  if 'google.colab' in sys.modules else False \r\n","\r\n","# google drive のマウント\r\n","if ENV_COLAB:\r\n","  from google.colab import drive \r\n","  drive.mount('/content/drive')\r\n","  os.chdir('/content/drive/My Drive/DNN_code/DNN_code_colab_day2/notebook')"],"outputs":[],"metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## sys.pathの設定"],"metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import sys\r\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定"],"outputs":[],"metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["# overfiting"],"metadata":{"id":"dYzVwNPlpQ4P","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","from collections import OrderedDict\r\n","from common import layers\r\n","from data.mnist import load_mnist\r\n","import matplotlib.pyplot as plt\r\n","from multi_layer_net import MultiLayerNet\r\n","from common import optimizer\r\n","\r\n","\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# 過学習を再現するために、学習データを削減\r\n","x_train = x_train[:300]\r\n","d_train = d_train[:300]\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\r\n","optimizer = optimizer.SGD(learning_rate=0.01)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    optimizer.update(network.params, grad)\r\n","\r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)\r\n","        \r\n","    if (i+1) % plot_interval == 0:\r\n","        accr_train = network.accuracy(x_train, d_train)\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_train.append(accr_train)\r\n","        accuracies_test.append(accr_test)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))        \r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"i1UkQeoupQ4Q","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## weight decay\n","### L2"],"metadata":{"id":"J143QSqnpQ4X","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["from common import optimizer\r\n","\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# 過学習を再現するために、学習データを削減\r\n","x_train = x_train[:300]\r\n","d_train = d_train[:300]\r\n","\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\r\n","\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate=0.01\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","hidden_layer_num = network.hidden_layer_num\r\n","\r\n","# 正則化強度設定 ======================================\r\n","weight_decay_lambda = 0.1\r\n","# =================================================\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    weight_decay = 0\r\n","    \r\n","    for idx in range(1, hidden_layer_num+1):\r\n","        grad['W' + str(idx)] = network.layers['Affine' + str(idx)].dW + weight_decay_lambda * network.params['W' + str(idx)]\r\n","        grad['b' + str(idx)] = network.layers['Affine' + str(idx)].db\r\n","        network.params['W' + str(idx)] -= learning_rate * grad['W' + str(idx)]\r\n","        network.params['b' + str(idx)] -= learning_rate * grad['b' + str(idx)]        \r\n","        weight_decay += 0.5 * weight_decay_lambda * np.sqrt(np.sum(network.params['W' + str(idx)] ** 2))\r\n","\r\n","    loss = network.loss(x_batch, d_batch) + weight_decay\r\n","    train_loss_list.append(loss)        \r\n","        \r\n","    if (i+1) % plot_interval == 0:\r\n","        accr_train = network.accuracy(x_train, d_train)\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_train.append(accr_train)\r\n","        accuracies_test.append(accr_test)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \r\n","\r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"jbBEEaPUpQ4Z","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["### L1"],"metadata":{"id":"FggnvzajpQ4c","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# 過学習を再現するために、学習データを削減\r\n","x_train = x_train[:300]\r\n","d_train = d_train[:300]\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\r\n","\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate=0.1\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","hidden_layer_num = network.hidden_layer_num\r\n","\r\n","# 正則化強度設定 ======================================\r\n","weight_decay_lambda = 0.005\r\n","# =================================================\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    weight_decay = 0\r\n","    \r\n","    for idx in range(1, hidden_layer_num+1):\r\n","        grad['W' + str(idx)] = network.layers['Affine' + str(idx)].dW + weight_decay_lambda * np.sign(network.params['W' + str(idx)])\r\n","        grad['b' + str(idx)] = network.layers['Affine' + str(idx)].db\r\n","        network.params['W' + str(idx)] -= learning_rate * grad['W' + str(idx)]\r\n","        network.params['b' + str(idx)] -= learning_rate * grad['b' + str(idx)]        \r\n","        weight_decay += weight_decay_lambda * np.sum(np.abs(network.params['W' + str(idx)]))\r\n","\r\n","    loss = network.loss(x_batch, d_batch) + weight_decay\r\n","    train_loss_list.append(loss)        \r\n","        \r\n","    if (i+1) % plot_interval == 0:\r\n","        accr_train = network.accuracy(x_train, d_train)\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_train.append(accr_train)\r\n","        accuracies_test.append(accr_test)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \r\n","                \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"89ha__AQpQ4e","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["----------------------------------------------------------------------------------------------------------------------------------------\n","## [try] weigth_decay_lambdaの値を変更して正則化の強さを確認しよう\n","----------------------------------------------------------------------------------------------------------------------------------------"],"metadata":{"id":"yzxRlikgpQ4h","colab_type":"text"}},{"cell_type":"markdown","source":["## Dropout"],"metadata":{"id":"nmdVHCf4pQ4h","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["class Dropout:\r\n","    def __init__(self, dropout_ratio=0.5):\r\n","        self.dropout_ratio = dropout_ratio\r\n","        self.mask = None\r\n","\r\n","    def forward(self, x, train_flg=True):\r\n","        if train_flg:\r\n","            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\r\n","            return x * self.mask\r\n","        else:\r\n","            return x * (1.0 - self.dropout_ratio)\r\n","\r\n","    def backward(self, dout):\r\n","        return dout * self.mask"],"outputs":[],"metadata":{"id":"CwGTs1ktpQ4i","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["from common import optimizer\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# 過学習を再現するために、学習データを削減\r\n","x_train = x_train[:300]\r\n","d_train = d_train[:300]\r\n","\r\n","# ドロップアウト設定 ======================================\r\n","use_dropout = True\r\n","dropout_ratio = 0.15\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\r\n","                        weight_decay_lambda=weight_decay_lambda, use_dropout = use_dropout, dropout_ratio = dropout_ratio)\r\n","optimizer = optimizer.SGD(learning_rate=0.01)\r\n","# optimizer = optimizer.Momentum(learning_rate=0.01, momentum=0.9)\r\n","# optimizer = optimizer.AdaGrad(learning_rate=0.01)\r\n","# optimizer = optimizer.Adam()\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    optimizer.update(network.params, grad)\r\n","\r\n","    loss = network.loss(x_batch, d_batch)\r\n","    train_loss_list.append(loss)    \r\n","    \r\n","    if (i+1) % plot_interval == 0:\r\n","        accr_train = network.accuracy(x_train, d_train)\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_train.append(accr_train)\r\n","        accuracies_test.append(accr_test)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))        \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"tDyPfHnypQ4l","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","## [try] dropout_ratioの値を変更してみよう"],"metadata":{"id":"VGuvqCqspQ4n","colab_type":"text"}},{"cell_type":"markdown","source":["## [try] optimizerとdropout_ratioの値を変更してみよう\n","---------------------------------------------------------------------------------------------------------------------------------------------------------------------"],"metadata":{"id":"3f1NDPM4pQ4o","colab_type":"text"}},{"cell_type":"markdown","source":["## Dropout + L1"],"metadata":{"id":"QqLQuYOEpQ4p","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["from common import optimizer\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# 過学習を再現するために、学習データを削減\r\n","x_train = x_train[:300]\r\n","d_train = d_train[:300]\r\n","\r\n","# ドロップアウト設定 ======================================\r\n","use_dropout = True\r\n","dropout_ratio = 0.08\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\r\n","                        use_dropout = use_dropout, dropout_ratio = dropout_ratio)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate=0.01\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","hidden_layer_num = network.hidden_layer_num\r\n","\r\n","plot_interval=10\r\n","\r\n","# 正則化強度設定 ======================================\r\n","weight_decay_lambda=0.004\r\n","# =================================================\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    weight_decay = 0\r\n","    \r\n","    for idx in range(1, hidden_layer_num+1):\r\n","        grad['W' + str(idx)] = network.layers['Affine' + str(idx)].dW + weight_decay_lambda * np.sign(network.params['W' + str(idx)])\r\n","        grad['b' + str(idx)] = network.layers['Affine' + str(idx)].db\r\n","        network.params['W' + str(idx)] -= learning_rate * grad['W' + str(idx)]\r\n","        network.params['b' + str(idx)] -= learning_rate * grad['b' + str(idx)]        \r\n","        weight_decay += weight_decay_lambda * np.sum(np.abs(network.params['W' + str(idx)]))\r\n","\r\n","    loss = network.loss(x_batch, d_batch) + weight_decay\r\n","    train_loss_list.append(loss)        \r\n","        \r\n","    if (i+1) % plot_interval == 0:\r\n","        accr_train = network.accuracy(x_train, d_train)\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_train.append(accr_train)\r\n","        accuracies_test.append(accr_test)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"DAQfDEQUpQ4p","colab_type":"code","colab":{}}}]}