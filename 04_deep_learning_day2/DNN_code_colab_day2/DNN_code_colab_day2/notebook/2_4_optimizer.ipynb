{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('TE-BF': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"2_4_optimizer.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"interpreter":{"hash":"2c3a34dd19fbdd77fd1dec8c9940eb4c5c35bf3189654ec1682d5f40120b0240"}},"cells":[{"cell_type":"markdown","source":["# 準備"],"metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"}},{"cell_type":"markdown","source":["## Google Colab 用の処理\r\n","\r\n","下記を実行します\r\n","- ドライブのマウント\r\n","- ノートブックファイルと同じフォルダへの移動 \r\n","\r\n","Googleドライブのマイドライブ を基準に DNN_code/DNN_code_colab_day2 フォルダを置くことを仮定しています。必要に応じて，パスを変更してください．"],"metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# Google Colab での実行かを調べる\r\n","import sys\r\n","import os\r\n","ENV_COLAB = True  if 'google.colab' in sys.modules else False \r\n","\r\n","# google drive のマウント\r\n","if ENV_COLAB:\r\n","  from google.colab import drive \r\n","  drive.mount('/content/drive')\r\n","  os.chdir('/content/drive/My Drive/DNN_code/DNN_code_colab_day2/notebook')"],"outputs":[],"metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## sys.pathの設定"],"metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import sys\r\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定"],"outputs":[],"metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["# optimizer"],"metadata":{"id":"Psu3XXuHoXUx","colab_type":"text"}},{"cell_type":"markdown","source":["## SGD"],"metadata":{"id":"u9LK6Z0goXUy","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["import sys, os\r\n","sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\r\n","import numpy as np\r\n","from collections import OrderedDict\r\n","from common import layers\r\n","from data.mnist import load_mnist\r\n","import matplotlib.pyplot as plt\r\n","from multi_layer_net import MultiLayerNet\r\n","\r\n","\r\n","# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# batch_normalizationの設定 ================================\r\n","# use_batchnorm = True\r\n","use_batchnorm = False\r\n","# ====================================================\r\n","\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\r\n","                       use_batchnorm=use_batchnorm)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.01\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        network.params[key] -= learning_rate * grad[key]\r\n","        \r\n","        loss = network.loss(x_batch, d_batch)\r\n","        train_loss_list.append(loss)\r\n","    \r\n","    \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","\r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"RdlXeYygoXUz","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Momentum"],"metadata":{"id":"Enxu2WoaoXU4","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["\r\n","# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# batch_normalizationの設定 ================================\r\n","# use_batchnorm = True\r\n","use_batchnorm = False\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\r\n","                       use_batchnorm=use_batchnorm)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.01\r\n","# 慣性\r\n","momentum = 0.9\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    if i == 0:\r\n","        v = {}\r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        if i == 0:\r\n","            v[key] = np.zeros_like(network.params[key])\r\n","        v[key] = momentum * v[key] - learning_rate * grad[key]\r\n","        network.params[key] += v[key]\r\n","\r\n","        loss = network.loss(x_batch, d_batch)\r\n","        train_loss_list.append(loss)\r\n","        \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"2a6WWmpwoXU4","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## MomentumをもとにAdaGradを作ってみよう\n","θ = 1e-4 とする"],"metadata":{"id":"cpK_2sFVoXU7","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# AdaGradを作ってみよう\r\n","# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# batch_normalizationの設定 ================================\r\n","# use_batchnorm = True\r\n","use_batchnorm = False\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\r\n","                       use_batchnorm=use_batchnorm)\r\n","\r\n","iters_num = 1000\r\n","# iters_num = 500 # 処理を短縮\r\n","\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.01\r\n","\r\n","# AdaGradでは不必要\r\n","# =============================\r\n","\r\n","momentum = 0.9 \r\n","\r\n","# =============================\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    if i == 0:\r\n","        h = {}\r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","            \r\n","        # 変更しよう  \r\n","        # ===========================================\r\n","        if i == 0:\r\n","            h[key] = np.zeros_like(network.params[key])        \r\n","        h[key] = momentum * h[key] - learning_rate * grad[key]\r\n","        network.params[key] += h[key]\r\n","\r\n","        # ===========================================\r\n","        \r\n","        loss = network.loss(x_batch, d_batch)\r\n","        train_loss_list.append(loss)\r\n","        \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","\r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"A7zrjiFqoXU8","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## RSMprop"],"metadata":{"id":"l_UawNH_oXU_","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["\r\n","# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# batch_normalizationの設定 ================================\r\n","# use_batchnorm = True\r\n","use_batchnorm = False\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\r\n","                       use_batchnorm=use_batchnorm)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.01\r\n","decay_rate = 0.99\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    if i == 0:\r\n","        h = {}\r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        if i == 0:\r\n","            h[key] = np.zeros_like(network.params[key])\r\n","        h[key] *= decay_rate\r\n","        h[key] += (1 - decay_rate) * np.square(grad[key])\r\n","        network.params[key] -= learning_rate * grad[key] / (np.sqrt(h[key]) + 1e-7)\r\n","\r\n","        loss = network.loss(x_batch, d_batch)\r\n","        train_loss_list.append(loss)                \r\n","        \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","        \r\n","        \r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"LfBe2GcpoXVB","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Adam"],"metadata":{"id":"b8AuEm-YoXVD","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["\r\n","# データの読み込み\r\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\r\n","\r\n","print(\"データ読み込み完了\")\r\n","\r\n","# batch_normalizationの設定 ================================\r\n","# use_batchnorm = True\r\n","use_batchnorm = False\r\n","# ====================================================\r\n","\r\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\r\n","                       use_batchnorm=use_batchnorm)\r\n","\r\n","iters_num = 1000\r\n","train_size = x_train.shape[0]\r\n","batch_size = 100\r\n","learning_rate = 0.01\r\n","beta1 = 0.9\r\n","beta2 = 0.999\r\n","\r\n","train_loss_list = []\r\n","accuracies_train = []\r\n","accuracies_test = []\r\n","\r\n","plot_interval=10\r\n","\r\n","for i in range(iters_num):\r\n","    batch_mask = np.random.choice(train_size, batch_size)\r\n","    x_batch = x_train[batch_mask]\r\n","    d_batch = d_train[batch_mask]\r\n","\r\n","    # 勾配\r\n","    grad = network.gradient(x_batch, d_batch)\r\n","    if i == 0:\r\n","        m = {}\r\n","        v = {}\r\n","    learning_rate_t  = learning_rate * np.sqrt(1.0 - beta2 ** (i + 1)) / (1.0 - beta1 ** (i + 1))    \r\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\r\n","        if i == 0:\r\n","            m[key] = np.zeros_like(network.params[key])\r\n","            v[key] = np.zeros_like(network.params[key])\r\n","            \r\n","        m[key] += (1 - beta1) * (grad[key] - m[key])\r\n","        v[key] += (1 - beta2) * (grad[key] ** 2 - v[key])            \r\n","        network.params[key] -= learning_rate_t * m[key] / (np.sqrt(v[key]) + 1e-7)                \r\n","        \r\n","        \r\n","    if (i + 1) % plot_interval == 0:\r\n","        accr_test = network.accuracy(x_test, d_test)\r\n","        accuracies_test.append(accr_test)        \r\n","        accr_train = network.accuracy(x_batch, d_batch)\r\n","        accuracies_train.append(accr_train)\r\n","        loss = network.loss(x_batch, d_batch)\r\n","        train_loss_list.append(loss)        \r\n","        \r\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\r\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\r\n","                \r\n","\r\n","lists = range(0, iters_num, plot_interval)\r\n","plt.plot(lists, accuracies_train, label=\"training set\")\r\n","plt.plot(lists, accuracies_test,  label=\"test set\")\r\n","plt.legend(loc=\"lower right\")\r\n","plt.title(\"accuracy\")\r\n","plt.xlabel(\"count\")\r\n","plt.ylabel(\"accuracy\")\r\n","plt.ylim(0, 1.0)\r\n","# グラフの表示\r\n","plt.show()"],"outputs":[],"metadata":{"id":"pLDbV89JoXVE","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","## [try] 学習率を変えてみよう"],"metadata":{"id":"vES2U8SwoXVH","colab_type":"text"}},{"cell_type":"markdown","source":["## [try] 活性化関数と重みの初期化方法を変えてみよう\n","初期状態ではsigmoid - gauss<br>\n","activationはReLU、weight_init_stdは別の数値や'Xavier'・'He'に変更可能"],"metadata":{"id":"7MMdi7-DoXVI","colab_type":"text"}},{"cell_type":"markdown","source":["## [try] バッチ正規化をしてみよう\n","use_batchnormをTrueにしよう\n","\n","---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"],"metadata":{"id":"hqBzhXJDoXVI","colab_type":"text"}}]}